---
layout: default
title: Über Mich
font_family: "Montserrat"
text_align: justify
lang: de
---

<div class="container_center">
  <img src="{{ site.profile_image }}" alt="{{ site.my_name.de }} Profilbild" class="logo" />
</div>

# <i class="fa fa-user"></i> Über Mich

Hallo, mein Name ist {{ site.my_name.de }}. Ich bin {{ site.my_role.de }} mit einer Promotion in Astrophysik und verfüge über mehr als {{ site.n_exp_years }} Jahre Erfahrung in der Anwendung fortgeschrittener Datenanalyse- und KI-Prinzipien.
Meine Leidenschaft ist es, komplexe industrielle Daten in intelligente, handlungsrelevante Lösungen zu transformieren.

Mit **{{ site.company }}** ist es meine Mission, Technologieanbieter wie Sie zu unterstützen. Ich schließe die Lücke zwischen akademischer Forschung und den praktischen Anforderungen der Industriewelt und liefere:

- **Zukunftsweisende prädiktive Fähigkeiten** und robuste KI-gestützte Funktionen für Ihre Software.
- **Produktionsreife KI-Systeme**, die sich nahtlos integrieren, Falschalarme reduzieren und Ihren Kunden helfen, Ausfallzeiten zu minimieren und die Anlagenleistung zu optimieren.
- Einen **entscheidenden Wettbewerbsvorteil** für Ihre Softwareangebote.

Meine Erfolgsbilanz umfasst die **Verdoppelung des SaaS-Produktportfolios** bei einem Startup für Predictive Maintenance durch die Entwicklung und Implementierung hochentwickelter Algorithmen zur Anomalieerkennung und Diagnose. Mit über {{ site.n_exp_years }} Jahren Erfahrung in der Umwandlung von Petabytes an verrauschten, hochvolumigen Daten (von Astrophysik bis zu Industriesensoren) in klare Erkenntnisse, biete ich eine Mischung aus tiefer statistischer Rigorosität und pragmatischer Ingenieurskunst.

Ich arbeite partnerschaftlich mit Ihnen zusammen, um technisch exzellente KI-Lösungen zu entwickeln, die direkt zum Wert, zur Zuverlässigkeit und zur Marktführerschaft Ihres Produkts beitragen. Meine Kompetenzen umfassen:

- Die Verfeinerung bestehender Predictive-Maintenance-Modelle.
- Das Design skalierbarer MLOps-Pipelines.
- Die Integration fortschrittlicher Funktionalitäten von Large Language Models (LLM).

## <i class="fa fa-graduation-cap"></i> Ausbildung & Akademische Grundlagen

- 2010 **Diplom-Physiker (Univ.)** – Humboldt-Universität zu Berlin, _Deutschland_

  - Schwerpunkte: Experimentelle Astrophysik & Teilchenphysik.

- 2015 **Dr. rer. nat. in Astrophysik** – [Max-Planck-Institut für Astrophysik](https://www.mpa-garching.mpg.de/de) (MPA) & [Ludwig-Maximilians-Universität München](https://de.wikipedia.org/wiki/Ludwig-Maximilians-Universit%C3%A4t_M%C3%BCnchen) (LMU), _Deutschland_ (Note: magna cum laude, [Dissertation](https://edoc.ub.uni-muenchen.de/18228/))
  - Promotionsforschung am weltweit renommierten **Max-Planck-Institut für Astrophysik (MPA)** durchgeführt.
  - Spezialisiert auf die Analyse umfangreicher und komplexer Datensätze von Weltraumteleskopen (NASA & ESA), mit Fokus auf fortgeschrittene statistische Modellierung (einschließlich Bayes'scher Inferenz), **Zeitreihenanalyse**, Signalverarbeitung in verrauschten Umgebungen und innovative Problemlösungen.
  - Diese rigorose wissenschaftliche Ausbildung schuf ein starkes Fundament für die Entwicklung **robuster und zuverlässiger Lösungen** – Kernkompetenzen, die direkt auf die heutigen anspruchsvollen Herausforderungen in Data Science und KI in der Industrie übertragbar sind.
  - <a href="https://edoc.ub.uni-muenchen.de/18228/" target="_blank">Dissertation</a>

## <i class="fa fa-rocket"></i> Beruflicher Werdegang

### Von kosmischen Daten zu industriellen KI-Lösungen

- 2015 – 2021 **Forschungsleiter & Data Scientist (Astrophysik)** – [Max-Planck-Institut für Astrophysik](https://www.mpa-garching.mpg.de/de) (_Deutschland_), [Kavli Institute for Astronomy & Astrophysics](https://kiaa.pku.edu.cn) (_China_) & [Institut d'Astrophysique Spatiale](https://www.ias.u-psud.fr/fr/) (CNRS, _Frankreich_)

  - Leitung internationaler Forschungsprojekte zur Analyse von Petabyte-großen astronomischen Datensätzen, um aussagekräftige Erkenntnisse über kosmische Strukturen zu gewinnen.
  - Perfektionierung fortgeschrittener statistischer Methoden (z.B. Bayes'sche Inferenz, MCMC, Fourier-Analyse für **Zeitreihen**) und Anwendung von Machine-Learning-Techniken auf hochvolumige Daten, einschließlich der Entwicklung von Algorithmen zur **Signalerkennung in stark verrauschten Umgebungen** (vergleichbar mit Anomalieerkennung).
  - Entwicklung innovativer, **robuster** Python-basierter ETL-Pipelines und **skalierbarer** Analysewerkzeuge, die die methodische Strenge und Problemlösungskompetenz demonstrieren, die für die anspruchsvollen industriellen Datenlandschaften von heute unerlässlich sind.
  - Verfassen von Erstautor-Publikationen in führenden, begutachteten Fachzeitschriften (z.B. _Astronomy & Astrophysics_) und Einwerbung kompetitiver Forschungsgelder, was eine tiefe analytische Expertise unterstreicht. ([Publikationsliste](https://ui.adsabs.harvard.edu/search/q=author%3A"Kolodzig"))

- 2022 – 2024 **Data Scientist** – Metroscope (EDF-Tochterunternehmen), _Paris, Frankreich_
  - Anwendung von Data-Science- & KI-Expertise zur Entwicklung, Implementierung und Verbesserung hochmoderner, **zuverlässiger Predictive Maintenance (PdM)**-Lösungen für den Energiesektor.
  - Meine Arbeit trug direkt zur Verbesserung der Modellgenauigkeit und zur **Verdoppelung des SaaS-Produktportfolios des Unternehmens** bei.
  - **Wesentliche Beiträge zu industrieller KI-Software:**
    - Entwicklung, Modernisierung und Implementierung hochentwickelter Algorithmen zur **Anomalieerkennung** und **Anlagenleistungsdiagnose**.
    - Aufbau und Implementierung robuster ETL-Pipelines zur Verarbeitung heterogener industrieller Kundendaten, um Datenqualität und -verfügbarkeit für fortschrittliche Analysen sicherzustellen.
    - **Erweiterung physikalischer Modelle** durch fortschrittliche statistische und Machine-Learning-Ansätze (Grundlagen für physikinforrmiertes Maschinelles Lernen).
  - _Für weitere Details siehe <a href="{{ site.baseurl }}/de/portfolio">mein Portfolio</a>._

## <i class="fa fa-wrench"></i> Schlüsseltechnologien & Expertise

Mein Ansatz kombiniert tiefes theoretisches Verständnis mit praxisnaher Expertise in den Technologien, die moderne industrielle KI-Lösungen antreiben. Ich bin spezialisiert auf die Entwicklung und Implementierung robuster, skalierbarer Systeme, die einen greifbaren Mehrwert liefern:

- **Maschinelles Lernen für Predictive Maintenance & Anomalieerkennung:**

  - **Zeitreihenanalyse & -prognose:** Fortschrittliche Techniken zur Vorhersage zukünftiger Zustände, Trends und der Restnutzungsdauer (RUL).
  - **Algorithmen zur Anomalieerkennung:** Expertise in überwachten und unüberwachten Methoden (z.B. Clustering, PCA, Autoencoder) zur Identifizierung subtiler Abweichungen und Frühwarnzeichen in Sensordaten.
  - **Prädiktive Modellierung:** Regression, Klassifikation und Ensemble-Methoden (z.B. XGBoost, Random Forests) zur Vorhersage von Anlagenausfällen und zur Leistungsoptimierung.
  - **Physikinforrmiertes Maschinelles Lernen (PIML):** Integration von Domänenwissen in datengesteuerte Modelle zur Steigerung von Genauigkeit und Interpretierbarkeit.
  - **Modellevaluierung & -optimierung:** Rigorose Kreuzvalidierung, Hyperparameter-Tuning und Feature Engineering für Spitzenleistung.

- **Integration von LLM & Generativer KI:**

  - **Retrieval-Augmented Generation (RAG):** Aufbau von Chatbots und Q&A-Systemen auf Basis benutzerdefinierter industrieller Wissensdatenbanken (z.B. technische Dokumentationen, Wartungsprotokolle).
  - **LLM-Anwendungsentwicklung:** Nutzung von APIs (OpenAI, Groq, Google Gemini) und Open-Source-Modellen (Mistral, Llama) für Aufgaben wie automatische Berichterstellung, Zusammenfassung von Erkenntnissen und intelligente Suche.
  - **Prompt Engineering & Vektordatenbanken:** Erstellung effektiver Prompts und Nutzung von Vektorsuche (z.B. LanceDB) zur relevanten Informationsbeschaffung.

- **MLOps & Produktiveinsatz:**

  - **Modellbereitstellung & -Serving:** Erstellung und Bereitstellung von ML-Modellen als skalierbare Dienste (REST APIs via Flask/FastAPI, Docker, Kubernetes).
  - **CI/CD & Automatisierung:** Implementierung von Continuous-Integration- & Deployment-Pipelines (GitHub Actions) für effiziente Entwicklungszyklen.
  - **Monitoring & Erklärbarkeit:** Einrichtung von Modellüberwachung (Grafana) und Nutzung von Werkzeugen wie SHAP zur Modellinterpretierbarkeit.
  - **Versionskontrolle:** MLflow für Experimentverfolgung und Modellversionierung; Git für Codeverwaltung.

- **Data Engineering & -verarbeitung:**

  - **ETL-Pipelines:** Konzeption und Implementierung robuster Pipelines für Datenaufnahme, -bereinigung, -validierung und -transformation für heterogene Industriedaten.
  - **Datenmanagement & -speicherung:** Versiert im Umgang mit SQL- (PostgreSQL) und NoSQL- (MongoDB) Datenbanken sowie Big-Data-Verarbeitungswerkzeugen (Dask).
  - **Cloud-Plattformen:** Erfahrung mit Azure-Diensten für Datenorchestrierung und -speicherung.

- **Kernkompetenzen Programmierung & Werkzeuge:**
  - **Sprachen:** Python (primär), SQL, Shell-Skripting
  - **Bibliotheken:** Scikit-learn, Pandas, NumPy, Matplotlib, Plotly, Dask
  - **Entwicklungswerkzeuge:** Jupyter Notebooks, VS Code, Docker, Git, Linux
