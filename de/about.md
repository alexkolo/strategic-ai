---
layout: default
title: Über Mich
font_family: "Montserrat"
text_align: justify
lang: de
noindex: true
---

<div class="container_center">
  <img src="{{ site.profile_image }}" alt="{{ site.my_name.de }} Profilbild" class="logo" />
</div>

# <i class="fa fa-user"></i> Über Mich

Hallo, mein Name ist {{ site.my_name.de }}. Ich bin {{ site.my_role.de }} mit einer Promotion in Astrophysik und verfüge über mehr als {{ site.n_exp_years }} Jahre Erfahrung in der Anwendung fortgeschrittener Datenanalyse- und KI-Prinzipien.
Meine Leidenschaft ist es, komplexe industrielle und wissenschaftliche Daten in intelligente, handlungsrelevante Lösungen zu transformieren, die einen echten Mehrwert schaffen.

Meine Mission ist es, sowohl **Technologieanbieter als auch industrielle Endanwender zu unterstützen.** Technologieanbieter unterstütze ich dabei, ihre Software mit strategischer KI zu optimieren. Industriellen Endanwendern biete ich Expertenberatung, um ihnen zu helfen, sich in der KI-Landschaft zurechtzufinden und effektive datengesteuerte Strategien zu implementieren.
Ich schließe die Lücke zwischen akademischer Forschung und den praktischen Anforderungen der Industriewelt und liefere:

- **Für Softwareanbieter:** Zukunftsweisende prädiktive Fähigkeiten und robuste KI-gestützte Funktionen, die einen deutlichen Wettbewerbsvorteil bieten.
- **Für Anlagenbetreiber:** Klare, unabhängige Beratung und Strategien, um KI für eine optimierte Anlagenleistung und reduzierte Betriebsrisiken zu nutzen.
- **Für Beide:** Produktionsreife KI-Systeme und -Lösungen, die sich nahtlos integrieren und messbaren Mehrwert liefern.

Meine Erfolgsbilanz umfasst die **Verdoppelung des SaaS-Produktportfolios** bei einem Startup für Predictive Maintenance durch die Entwicklung und Implementierung hochentwickelter Algorithmen zur Anomalieerkennung und Diagnose. Mit über {{ site.n_exp_years }} Jahren Erfahrung in der Umwandlung von Petabytes an verrauschten, hochvolumigen Daten (von Astrophysik bis zu Industriesensoren) in klare Erkenntnisse, biete ich eine Mischung aus tiefer statistischer Rigorosität und pragmatischer Ingenieurskunst – Fähigkeiten, die sowohl für die KI-Entwicklung als auch für die strategische Beratung unerlässlich sind.

Ich arbeite partnerschaftlich mit Ihnen zusammen, um **technisch exzellente KI-Lösungen zu entwickeln oder datengestützte Strategien zu formulieren**, die direkt zum Wert Ihres Produkts, Ihrer operativen Effizienz und Ihrer Marktführerschaft beitragen. Meine Kompetenzen umfassen:

- Die Verfeinerung bestehender Predictive-Maintenance-Modelle oder die Beratung zu deren Auswahl.
- Das Design skalierbarer MLOps-Pipelines für robuste KI-Implementierungen.
- Die Integration fortschrittlicher Funktionalitäten von Large Language Models (LLM) oder die Beratung zu deren industrieller Anwendung.
- Die Bewertung der Datenreadiness und die Entwicklung von KI-Roadmaps für industrielle Betriebe.

## <i class="fa fa-graduation-cap"></i> Ausbildung & Akademische Grundlagen

- 2010 **Diplom-Physiker (Univ.)** – Humboldt-Universität zu Berlin, _Deutschland_

  - Schwerpunkte: Experimentelle Astrophysik & Teilchenphysik.

- 2015 **Dr. rer. nat. in Astrophysik** – [Max-Planck-Institut für Astrophysik](https://www.mpa-garching.mpg.de/de) (MPA) & [Ludwig-Maximilians-Universität München](https://de.wikipedia.org/wiki/Ludwig-Maximilians-Universit%C3%A4t_M%C3%BCnchen) (LMU), _Deutschland_
  - Promotionsforschung am weltweit renommierten **Max-Planck-Institut für Astrophysik (MPA)** durchgeführt.
  - Spezialisiert auf die Analyse umfangreicher und komplexer Datensätze von Weltraumteleskopen (NASA & ESA), mit Fokus auf fortgeschrittene statistische Modellierung (einschließlich Bayes'scher Inferenz), **Zeitreihenanalyse**, Signalverarbeitung in verrauschten Umgebungen und innovative Problemlösungen.
  - Diese rigorose wissenschaftliche Ausbildung schuf ein starkes Fundament für die Entwicklung **robuster und zuverlässiger Lösungen** – Kernkompetenzen, die direkt auf die heutigen anspruchsvollen Herausforderungen in Data Science und KI in der Industrie übertragbar sind, sei es in der Softwareentwicklung oder der strategischen Beratung.
  - <a href="https://edoc.ub.uni-muenchen.de/18228/" target="_blank">Dissertation</a>

## <i class="fa fa-rocket"></i> Beruflicher Werdegang

### Von kosmischen Daten zu industriellen KI-Lösungen

- 2015 – 2021 **Forschungsleiter & Data Scientist (Astrophysik)** – [Max-Planck-Institut für Astrophysik](https://www.mpa-garching.mpg.de/de) (_Deutschland_), [Kavli Institute for Astronomy & Astrophysics](https://kiaa.pku.edu.cn) (_China_) & [Institut d'Astrophysique Spatiale](https://www.ias.u-psud.fr/fr/) (CNRS, _Frankreich_)

  - Leitung internationaler Forschungsprojekte zur Analyse von Petabyte-großen astronomischen Datensätzen, um aussagekräftige Erkenntnisse aus komplexen Signalen zu gewinnen. Dies schulte meine Fähigkeiten im Umgang mit **Big Data, der Entwicklung innovativer Analysemethoden und der Gewinnung von Mehrwert aus verrauschten, komplexen Informationsströmen** – grundlegend für industrielle KI.
  - Perfektionierung fortgeschrittener statistischer Methoden (z.B. Bayes'sche Inferenz, MCMC, Fourier-Analyse für **Zeitreihen**) und Anwendung von Machine-Learning-Techniken auf hochvolumige Daten, einschließlich der Entwicklung von Algorithmen zur **Signalerkennung in stark verrauschten Umgebungen** (vergleichbar mit Anomalieerkennung).
  - Entwicklung innovativer, **robuster** Python-basierter ETL-Pipelines und **skalierbarer** Analysewerkzeuge, die die methodische Strenge und Problemlösungskompetenz demonstrieren, die für die anspruchsvollen industriellen Datenlandschaften von heute unerlässlich sind.
  - Verfassen von Erstautor-Publikationen in führenden, begutachteten Fachzeitschriften (z.B. _Astronomy & Astrophysics_) und Einwerbung kompetitiver Forschungsgelder, was eine tiefe analytische Expertise unterstreicht. ([Publikationsliste](https://ui.adsabs.harvard.edu/search/q=author%3A"Kolodzig"))

- 2022 – 2024 **Data Scientist** – Metroscope (EDF-Tochterunternehmen), _Paris, Frankreich_

  - Anwendung von Data-Science- & KI-Expertise zur Entwicklung, Implementierung und Verbesserung hochmoderner, **zuverlässiger Predictive Maintenance (PdM)**-Lösungen für den Energiesektor. Diese Rolle umfasste tiefgehende Einblicke in **sowohl die KI-Produktentwicklung als auch das Verständnis der praktischen Bedürfnisse von Anlagenbetreibern.**
  - Meine Arbeit trug direkt zur Verbesserung der Modellgenauigkeit und zur **Verdoppelung des SaaS-Produktportfolios des Unternehmens** bei.
  - **Wesentliche Beiträge zur industriellen KI-Software & zum Verständnis von Endanwender-Bedürfnissen:**
    - Entwicklung, Modernisierung und Implementierung hochentwickelter Algorithmen zur **Anomalieerkennung** und **Anlagenleistungsdiagnose**.
    - Aufbau und Implementierung robuster ETL-Pipelines zur Verarbeitung heterogener industrieller Kundendaten, um Datenqualität und -verfügbarkeit für fortschrittliche Analysen sicherzustellen.
    - **Erweiterung physikalischer Modelle** durch fortschrittliche statistische und Machine-Learning-Ansätze (Grundlagen für physikinforrmiertes Maschinelles Lernen).
  - _Diese Erfahrungen fließen direkt in meine Dienstleistungen ein, wie in <a href="{{ site.baseurl }}/de/portfolio">Mein Portfolio</a> detailliert beschrieben._

- Ab 2025 **{{ site.my_role.de }}** – {{ site.company }} (Einzelunternehmen), _Paris, Frankreich_
  - Details zu meinen Dienstleistungen für **Technologieanbieter** und **Anlagenbetreiber** finden Sie unter <a href="{{ site.baseurl }}/de/services_build">Meine Leistungen</a>.

## <i class="fa fa-wrench"></i> Schlüsseltechnologien & Expertise

Mein Ansatz kombiniert tiefes theoretisches Verständnis mit praxisnaher Expertise in den Technologien, die moderne industrielle KI-Lösungen antreiben. Ich bin spezialisiert auf die Entwicklung und Implementierung robuster, skalierbarer Systeme sowie auf die strategische Beratung zu deren Anwendung, um einen greifbaren Mehrwert zu liefern:

- **Maschinelles Lernen für Predictive Maintenance & Anomalieerkennung:**

  - **Zeitreihenanalyse & -prognose:** Fortschrittliche Techniken zur Vorhersage zukünftiger Zustände, Trends und der Restnutzungsdauer (RUL).
  - **Algorithmen zur Anomalieerkennung:** Expertise in überwachten und unüberwachten Methoden (z.B. Clustering, PCA, Autoencoder) zur Identifizierung subtiler Abweichungen und Frühwarnzeichen in Sensordaten.
  - **Prädiktive Modellierung:** Regression, Klassifikation und Ensemble-Methoden (z.B. XGBoost, Random Forests) zur Vorhersage von Anlagenausfällen und zur Leistungsoptimierung.
  - **Physikinforrmiertes Maschinelles Lernen (PIML):** Integration von Domänenwissen in datengesteuerte Modelle zur Steigerung von Genauigkeit und Interpretierbarkeit.
  - **Modellevaluierung & -optimierung:** Rigorose Kreuzvalidierung, Hyperparameter-Tuning und Feature Engineering für Spitzenleistung.

- **Integration von LLM & Generativer KI:**

  - **Retrieval-Augmented Generation (RAG):** Aufbau von Chatbots und Q&A-Systemen auf Basis benutzerdefinierter industrieller Wissensdatenbanken (z.B. technische Dokumentationen, Wartungsprotokolle).
  - **LLM-Anwendungsentwicklung:** Nutzung von APIs (OpenAI, Groq, Google Gemini) und Open-Source-Modellen (Mistral, Llama) für Aufgaben wie automatische Berichterstellung, Zusammenfassung von Erkenntnissen und intelligente Suche.
  - **Prompt Engineering & Vektordatenbanken:** Erstellung effektiver Prompts und Nutzung von Vektorsuche (z.B. LanceDB) zur relevanten Informationsbeschaffung.

- **MLOps & Produktiveinsatz:**

  - **Modellbereitstellung & -Serving:** Erstellung und Bereitstellung von ML-Modellen als skalierbare Dienste (REST APIs via Flask/FastAPI, Docker, Kubernetes).
  - **CI/CD & Automatisierung:** Implementierung von Continuous-Integration- & Deployment-Pipelines (GitHub Actions) für effiziente Entwicklungszyklen.
  - **Monitoring & Erklärbarkeit:** Einrichtung von Modellüberwachung (Grafana) und Nutzung von Werkzeugen wie SHAP zur Modellinterpretierbarkeit.
  - **Versionskontrolle:** MLflow für Experimentverfolgung und Modellversionierung; Git für Codeverwaltung.

- **Data Engineering & -verarbeitung:**

  - **ETL-Pipelines:** Konzeption und Implementierung robuster Pipelines für Datenaufnahme, -bereinigung, -validierung und -transformation für heterogene Industriedaten.
  - **Datenmanagement & -speicherung:** Versiert im Umgang mit SQL- (PostgreSQL) und NoSQL- (MongoDB) Datenbanken sowie Big-Data-Verarbeitungswerkzeugen (Dask).
  - **Cloud-Plattformen:** Erfahrung mit Azure-Diensten für Datenorchestrierung und -speicherung.

- **Kernkompetenzen Programmierung & Werkzeuge:**
  - **Sprachen:** Python (primär), SQL, Shell-Skripting
  - **Bibliotheken:** Scikit-learn, Pandas, NumPy, Matplotlib, Plotly, Dask
  - **Entwicklungswerkzeuge:** Jupyter Notebooks, VS Code, Docker, Git, Linux
